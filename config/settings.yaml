# Configuration Parameters Overview:
#
# Core System Configuration:
# - paths: File system paths for documents, embeddings, indexes, and knowledge graph data
# - chunking: Document segmentation parameters including size, overlap, and tokenization method
# - models: Machine learning model specifications for embeddings, reranking, and generation
#
# Query Processing and LLM Integration:
# - query_processing: LLM-based query filtering and enhancement configuration
# - evaluation: LLM judge parameters for response quality assessment with consistency controls
#
# Retrieval System Configuration:
# - enhanced_retrieval: Pool sizes and final result limits for multi-stage retrieval
# - retrieval: Sparse/dense fusion parameters and ranking methods
# - graph_retrieval: Knowledge graph symptom search thresholds and fallback strategies
# - hybrid_symptom_search: Multi-modal search combining BM25, FAISS, and Levenshtein distance
#
# Equipment and Knowledge Graph Management:
# - equipment_matching: Equipment entity matching thresholds and filtering strategies
# - kg_construction_hybrid: Hybrid metric parameters for knowledge graph construction
# - neo4j: Database connectivity for cloud and local Neo4j instances
#
# Generation and Post-Processing:
# - reranking: Cross-encoder reranking parameters and fallback mechanisms
# - generation: Context management, prompt configuration, and output constraints

# Main RAG System Configuration
# Updated with re-ranking support, complete pipeline, and LLM evaluation capabilities

paths:
  # Source documents
  raw_documents: data/documents/source_pdfs/
  json_documents: data/documents/extracted_json/
  chunk_documents: data/documents/processed_chunks/
  
  # Indexes and embeddings
  embeddings_dir: data/indexes/embeddings/
  embedding_file: data/indexes/embeddings/metadata.pkl
  bm25_index: data/indexes/lexical_bm25/
  faiss_index_dir: data/indexes/semantic_faiss/
  faiss_index: data/indexes/semantic_faiss/index.faiss
  
  # Knowledge Graph
  symptom_dense_dir: data/knowledge_base/symptom_embeddings_dense/
  symptom_dense_sc_dir: data/knowledge_base/symptom_embedding_dense_sc/
  symptom_sparse_dir: data/knowledge_base/symptom_embedding_sparse/
  scr_triplets: data/knowledge_base/scr_triplets/
  bm25_index_path: data/knowledge_base/symptom_bm25_dense/
  bm25_sparse_index_path: data/knowledge_base/symptom_bm25_sparse/
  bm25_dense_sc_index_path: data/knowledge_base/symptom_bm25_dense_sc/

  # Output
  outputs: data/outputs/

chunking:
  chunk_size: 200       
  overlap: 100          
  tokenize_by: sentence  # word | sentence

# Query Processing and LLM Filter Configuration
query_processing:
  llm:
    provider: "openai"              # LLM provider (currently OpenAI only)
    model: "gpt-4o"                 # Fast and efficient model for preprocessing
    api_key: ${OPENAI_API_KEY}      # API key from environment variables
    temperature: 0.1                # Low temperature for precise extraction
    max_tokens: 1000                # Token limit for JSON response
    timeout: 30                     # Timeout in seconds
  
  processing:
    max_query_variants: 2           # Maximum number of query variants to generate
    fallback_on_llm_error: true     # Use original query if LLM fails

# Enhanced Retrieval Configuration
enhanced_retrieval:
  pool_size: 15                     # Initial candidate pool size
  final_chunk_top_k: 5              # Final number of chunks to return
  final_triplet_top_k: 3            # Final number of KG triplets to return

# Enhanced LLM Judge Evaluation
evaluation:
  llm_judge:
    model: "gpt-4o"                     # Advanced model for consistent evaluation
    temperature: 0.0                    # Maximum determinism
    max_tokens: 500                     # Increased space for detailed analysis
    
    # Consistency parameters
    seed: 42                            # Fixed seed for reproducibility
    top_p: 1.0                         # No nucleus sampling
    frequency_penalty: 0.0              # No frequency penalty
    presence_penalty: 0.0               # No presence penalty
    
    # Retry logic for consistency
    retry_on_inconsistency: true        # Retry if scores differ significantly for similar responses
    max_retries: 2                      # Maximum retry attempts
    similarity_threshold: 0.9           # Response similarity threshold for duplicate detection
    max_score_difference: 0.3           # Maximum allowed score difference for similar responses

retrieval:
  # Parameters for each retriever
  top_k_sparse: 10      # BM25 results before fusion
  top_k_dense: 10       # FAISS results before fusion
  fusion_weight: 0.5    # 50% lexical / 50% semantic
  
  # Fusion parameters
  fusion_method: average  # average | rrf | weighted
  rrf_k: 60              # Parameter for Reciprocal Rank Fusion

graph_retrieval:  
  # Symptom search parameters
  symptom_similarity_threshold: 0.8  # Similarity threshold for symptoms
  symptom_top_k: 3                   # Number of similar symptoms to retrieve
  
  # Symptom-specific parameters
  use_dense_kg: true      # Use Dense KB by default
  fallback_to_sparse: true # Fallback to Sparse KB if Dense fails

  # Dense KG construction parameters
  dense_similarity_threshold: 0.8    # Similarity threshold between symptoms
  dense_top_k_similar: 5             # Number of similar symptoms for propagation

# Equipment Matching Configuration
equipment_matching:
  similarity_threshold: 0.9          # Cosine similarity threshold for LLM â†” KG equipment
  use_equipment_filter: true         # Enable equipment-based filtering  
  fallback_to_all: true             # If no match found, search entire KG

# Hybrid Symptom Search Configuration
hybrid_symptom_search:
  enabled: true
  weights:
    bm25_alpha: 0.4
    faiss_beta: 0.4
    levenshtein_gamma: 0.2
  
  # BM25 index paths for different KG types
  bm25_index_path: data/knowledge_base/symptom_bm25_dense           # For Dense KG
  bm25_sparse_index_path: data/knowledge_base/symptom_bm25_sparse   # For Sparse KG
  bm25_dense_sc_index_path: data/knowledge_base/symptom_bm25_dense_sc # For Dense S&C KG
  
  levenshtein_threshold: 3

# Model Configuration
models:
  embedding_model: sentence-transformers/all-MiniLM-L6-v2
  reranker_model: cross-encoder/ms-marco-MiniLM-L-6-v2
  openai_model: gpt-4o   

reranking:
  enabled: true
  top_k_before_rerank: 10
  final_top_k: 3          
  fallback_on_error: true
  min_score_threshold: 0.0

generation:
  max_context_chunks: 3
  prompt_template: config/prompt_template.txt
  temperature: 0.0
  max_new_tokens: 1024
  importance_context_rerank: 50         
  importance_context_graph: 50
  top_k_triplets: 3  # Limit number of KG triplets
  seuil_pertinence: 0.7  # Relevance threshold for documents

# Neo4j Configuration - Cloud and Local Support
neo4j:
  # Cloud instances
  cloud_enabled: ${NEO4J_CLOUD_ENABLED}  # Control cloud vs local
  
  # Dense Cloud
  dense_cloud_uri: ${NEO4J_DENSE_CLOUD_URI}
  dense_cloud_user: neo4j
  dense_cloud_password: ${NEO4J_DENSE_CLOUD_PASS}
  
  # Sparse Cloud
  sparse_cloud_uri: ${NEO4J_SPARSE_CLOUD_URI}
  sparse_cloud_user: neo4j
  sparse_cloud_password: ${NEO4J_SPARSE_CLOUD_PASS}
  
  # Dense S&C Cloud
  dense_sc_cloud_uri: ${NEO4J_DENSE_SC_CLOUD_URI}
  dense_sc_cloud_user: neo4j
  dense_sc_cloud_password: ${NEO4J_DENSE_SC_CLOUD_PASS}
  
  # Local instances (fallback)
  # Dense Knowledge Base (enriched)
  dense_uri: ${NEO4J_URI_DENSE}
  dense_user: ${NEO4J_USER_DENSE}
  dense_password: ${NEO4J_PASS_DENSE}
  
  # Sparse Knowledge Base (raw)
  sparse_uri: ${NEO4J_URI_SPARSE}
  sparse_user: ${NEO4J_USER_SPARSE}
  sparse_password: ${NEO4J_PASS_SPARSE}
  
  # Dense S&C
  dense_sc_uri: ${NEO4J_URI_DENSE_SC}
  dense_sc_user: ${NEO4J_USER_DENSE_SC}
  dense_sc_password: ${NEO4J_PASS_DENSE_SC}
  
  # General configuration (backward compatibility)
  uri: ${NEO4J_URI_DENSE}
  username: ${NEO4J_USER_DENSE}
  password: ${NEO4J_PASS_DENSE}

# Hybrid Metric for KG Construction
kg_construction_hybrid:
  enabled: true                          # Enable hybrid metric for KG construction
  fallback_to_cosine: true              # Fallback to cosine if hybrid fails
  
  # Hybrid metric weights (identical to hybrid_symptom_search)
  weights:
    bm25_alpha: 0.4                     # BM25 component weight (lexical)
    faiss_beta: 0.4                     # FAISS component weight (semantic)
    levenshtein_gamma: 0.2              # Levenshtein component weight (error codes)
  
  # Construction parameters
  min_similarity_threshold: 0.1          # Minimum threshold to consider similarity
  max_iterations: 1000                   # Iteration limit to prevent timeout
  batch_size: 50                        # Batch size for chunk processing