#!/usr/bin/env python3
"""
Test du BM25Retriever lexical
Teste les fonctionnalitÃ©s de recherche et affiche les rÃ©sultats dÃ©taillÃ©s
"""

import sys
from pathlib import Path
import yaml
from typing import Dict, Any

# Ajouter le rÃ©pertoire racine au path pour les imports
sys.path.append(str(Path(__file__).parent.parent))

from core.retrieval_engine.lexical_search import BM25Retriever


def load_settings(config_path: str = "config/settings.yaml") -> Dict[str, Any]:
    """Charge la configuration depuis le fichier YAML"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def print_separator(title: str, char: str = "="):
    """Affiche un sÃ©parateur avec titre"""
    print(f"\n{char * 60}")
    print(f" {title}")
    print(f"{char * 60}")


def print_result(result: Dict, index: int):
    """Affiche un rÃ©sultat de recherche de maniÃ¨re formatÃ©e"""
    print(f"\nğŸ“„ RÃ‰SULTAT #{index + 1}")
    print(f"ğŸ†” Document: {result['document_id']}")
    print(f"ğŸ§© Chunk: {result['chunk_id']}")
    print(f"ğŸ“Š Score BM25: {result['score']:.4f}")
    print(f"ğŸ“ Mots: {result.get('word_count', 'N/A')}")
    print(f"ğŸ”¤ CaractÃ¨res: {result.get('char_count', 'N/A')}")
    print(f"â­ QualitÃ©: {result.get('quality_score', 'N/A')}")
    print(f"ğŸ“‚ Source: {result.get('source_file', 'N/A')}")
    print(f"ğŸ”§ MÃ©thode: {result.get('chunking_method', 'N/A')}")
    print(f"ğŸ“– TEXTE:")
    print("-" * 50)
    # Afficher le texte avec des retours Ã  la ligne pour la lisibilitÃ©
    text = result['text']
    words = text.split()
    lines = []
    current_line = []
    current_length = 0
    
    for word in words:
        if current_length + len(word) + 1 > 80:  # 80 caractÃ¨res par ligne
            if current_line:
                lines.append(' '.join(current_line))
                current_line = [word]
                current_length = len(word)
            else:
                lines.append(word)  # Mot trÃ¨s long
                current_length = 0
        else:
            current_line.append(word)
            current_length += len(word) + 1
    
    if current_line:
        lines.append(' '.join(current_line))
    
    for line in lines:
        print(line)
    print("-" * 50)


def test_basic_functionality():
    """Test les fonctionnalitÃ©s de base du retriever"""
    print_separator("TEST DES FONCTIONNALITÃ‰S DE BASE")
    
    try:
        # Chargement de la configuration
        settings = load_settings()
        index_dir = Path(settings["paths"]["bm25_index"])
        
        print(f"ğŸ“ Index BM25: {index_dir}")
        
        # VÃ©rification de l'existence de l'index
        if not index_dir.exists():
            print(f"âŒ Index BM25 non trouvÃ©: {index_dir}")
            print("ğŸ’¡ ExÃ©cutez d'abord: poetry run python scripts/04_index_bm25.py")
            return None
        
        # Initialisation du retriever (plus simple maintenant)
        print("\nğŸ”„ Initialisation du BM25Retriever...")
        retriever = BM25Retriever(index_dir=index_dir)
        print("âœ… Retriever initialisÃ© avec succÃ¨s")
        
        # Statistiques de l'index
        stats = retriever.get_document_stats()
        print(f"\nğŸ“Š STATISTIQUES DE L'INDEX:")
        print(f"   ğŸ“„ Total chunks: {stats['total_chunks']}")
        print(f"   ğŸ“‹ Documents uniques: {stats['unique_documents']}")
        print(f"   ğŸ“ˆ Chunks/document (moy): {stats['avg_chunks_per_doc']:.1f}")
        
        return retriever
        
    except Exception as e:
        print(f"âŒ Erreur initialisation: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_search_queries(retriever: BM25Retriever):
    """Test diffÃ©rentes requÃªtes de recherche"""
    print_separator("TEST DES REQUÃŠTES DE RECHERCHE")
    
    # RequÃªtes de test
    test_queries = [
        {
            "query": "I got the error ACAL-006 TPE operation error on the FANUC teach pendant. What should I do?",
            "description": "RequÃªte principale - Erreur FANUC ACAL-006",
            "top_k": 5
        },
        {
            "query": "FANUC error ACAL-006",
            "description": "RequÃªte simplifiÃ©e - Mots-clÃ©s FANUC",
            "top_k": 3
        },
        {
            "query": "TPE operation error teach pendant",
            "description": "RequÃªte technique - TPE teach pendant",
            "top_k": 3
        },
        {
            "query": "robot calibration error",
            "description": "RequÃªte gÃ©nÃ©rale - Erreur calibration",
            "top_k": 3
        },
        {
            "query": "diagnostic troubleshooting",
            "description": "RequÃªte gÃ©nÃ©rale - Diagnostic",
            "top_k": 3
        }
    ]
    
    for i, test_case in enumerate(test_queries):
        print_separator(f"REQUÃŠTE {i+1}: {test_case['description']}", "-")
        print(f"ğŸ” RequÃªte: \"{test_case['query']}\"")
        print(f"ğŸ“Š Top-K: {test_case['top_k']}")
        
        try:
            # Recherche normale
            results = retriever.search(
                query=test_case['query'], 
                top_k=test_case['top_k'],
                min_score=0.1  # Score minimum pour filtrer les rÃ©sultats peu pertinents
            )
            
            if not results:
                print("âŒ Aucun rÃ©sultat trouvÃ©")
                
                # Essayer une recherche debug pour comprendre
                debug_info = retriever.debug_search(test_case['query'], top_k=1)
                print(f"ğŸ› Debug - requÃªte nettoyÃ©e: \"{debug_info['cleaned_query']}\"")
                print(f"ğŸ› Debug - stats index: {debug_info['index_stats']}")
                continue
            
            print(f"âœ… {len(results)} rÃ©sultat(s) trouvÃ©(s)")
            
            # Affichage des rÃ©sultats
            for j, result in enumerate(results):
                print_result(result, j)
            
            # Analyse de la pertinence
            scores = [r['score'] for r in results]
            print(f"\nğŸ“ˆ ANALYSE DES SCORES:")
            print(f"   ğŸ¯ Score max: {max(scores):.4f}")
            print(f"   ğŸ“Š Score min: {min(scores):.4f}")
            print(f"   ğŸ“ˆ Score moyen: {sum(scores)/len(scores):.4f}")
            
        except Exception as e:
            print(f"âŒ Erreur recherche: {e}")
            import traceback
            traceback.print_exc()


def test_edge_cases(retriever: BM25Retriever):
    """Test des cas limites"""
    print_separator("TEST DES CAS LIMITES")
    
    edge_cases = [
        "",  # RequÃªte vide
        "   ",  # Espaces seulement
        "azertyuiopqsdfghjklm",  # Mot inexistant
        "a",  # RequÃªte trÃ¨s courte
        "the and or in on at",  # Mots courants seulement
        "error!!! ???",  # CaractÃ¨res spÃ©ciaux
        "FANUC FANUC FANUC error error error",  # RÃ©pÃ©titions
    ]
    
    for i, query in enumerate(edge_cases):
        print(f"\nğŸ§ª Cas limite {i+1}: \"{query}\"")
        try:
            results = retriever.search(query, top_k=2)
            print(f"   ğŸ“Š RÃ©sultats: {len(results)}")
            if results:
                print(f"   ğŸ¯ Meilleur score: {results[0]['score']:.4f}")
        except Exception as e:
            print(f"   âŒ Erreur: {e}")


def test_performance(retriever: BM25Retriever):
    """Test de performance basique"""
    print_separator("TEST DE PERFORMANCE")
    
    import time
    
    query = "FANUC error ACAL-006 TPE operation"
    num_searches = 10
    
    print(f"ğŸƒ Test de {num_searches} recherches avec: \"{query}\"")
    
    start_time = time.time()
    
    for i in range(num_searches):
        results = retriever.search(query, top_k=5)
        if i == 0:
            first_result_count = len(results)
    
    end_time = time.time()
    total_time = end_time - start_time
    avg_time = total_time / num_searches
    
    print(f"â±ï¸ Temps total: {total_time:.3f}s")
    print(f"âš¡ Temps moyen par recherche: {avg_time:.3f}s")
    print(f"ğŸ“Š {first_result_count} rÃ©sultats par recherche")
    print(f"ğŸš€ Recherches/seconde: {num_searches/total_time:.1f}")


def main():
    """Fonction principale du test"""
    print_separator("ğŸ§ª TEST DU BM25RETRIEVER LEXICAL ğŸ§ª")
    
    try:
        # Test des fonctionnalitÃ©s de base
        retriever = test_basic_functionality()
        
        if retriever is None:
            print("âŒ Impossible d'initialiser le retriever. ArrÃªt des tests.")
            return
        
        # Test des requÃªtes de recherche
        test_search_queries(retriever)
        
        # Test des cas limites
        test_edge_cases(retriever)
        
        # Test de performance
        test_performance(retriever)
        
        print_separator("âœ… TESTS TERMINÃ‰S AVEC SUCCÃˆS")
        print("ğŸ‰ Le BM25Retriever fonctionne correctement!")
        
    except Exception as e:
        print(f"âŒ ERREUR GLOBALE: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()