import os
import json
import re
import csv
from pathlib import Path
from typing import Dict, Any, List, Tuple
import yaml

def load_settings(config_path: str) -> Dict[str, Any]:
    """Charge la configuration depuis le fichier YAML"""
    # GÃ©rer l'exÃ©cution depuis le dossier scripts/
    if not os.path.exists(config_path):
        config_path = os.path.join("..", config_path)
    
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def extract_scr_triplets_with_pages(pages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Extrait les triplets SCR avec la mÃ©thode sÃ©quentielle optimisÃ©e
    Inclut le numÃ©ro de page pour chaque triplet
    """
    all_triplets = []
    
    # Construire un texte global avec marqueurs de pages
    full_text_with_markers = ""
    page_positions = {}  # position_char -> page_number
    current_pos = 0
    
    for page_data in pages:
        page_num = page_data["page_number"]
        page_text = page_data["text"]
        
        # Marquer le dÃ©but de cette page
        page_positions[current_pos] = page_num
        full_text_with_markers += page_text + "\n"
        current_pos = len(full_text_with_markers)
    
    # Trouver tous les codes d'erreur avec leurs positions
    error_codes_with_pos = []
    for match in re.finditer(r'[A-Z]+-\d+', full_text_with_markers):
        error_codes_with_pos.append({
            'code': match.group(),
            'start_pos': match.start(),
            'end_pos': match.end()
        })
    
    # Extraire les triplets pour chaque code d'erreur
    for i, error_info in enumerate(error_codes_with_pos):
        code = error_info['code']
        code_pos = error_info['start_pos']
        
        # DÃ©terminer le numÃ©ro de page pour ce code
        page_num = 1  # Par dÃ©faut
        for pos, page in page_positions.items():
            if pos <= code_pos:
                page_num = page
            else:
                break
        
        # DÃ©finir la fenÃªtre de recherche (jusqu'au prochain code ou fin de texte)
        if i < len(error_codes_with_pos) - 1:
            next_code_pos = error_codes_with_pos[i + 1]['start_pos']
            window = full_text_with_markers[code_pos:next_code_pos]
        else:
            # DerniÃ¨re occurrence - prendre jusqu'Ã  2000 caractÃ¨res
            window = full_text_with_markers[code_pos:code_pos + 2000]
        
        # Chercher cause et remedy dans cette fenÃªtre
        cause_match = re.search(r'Cause:\s*(.*?)(?=Remedy:|$)', window, re.DOTALL | re.IGNORECASE)
        remedy_match = re.search(r'Remedy:\s*(.*?)(?=$|\n\n|\d+\.\d+|[A-Z]+-\d+)', window, re.DOTALL | re.IGNORECASE)
        
        if cause_match and remedy_match:
            # Extraire le symptÃ´me (ligne avec le code d'erreur)
            symptom_match = re.search(rf'({re.escape(code)}.*?)(?=\s*Cause:|$)', window, re.IGNORECASE)
            symptom = symptom_match.group(1) if symptom_match else code
            
            # Nettoyer les textes extraits
            cause_text = clean_extracted_text(cause_match.group(1))
            remedy_text = clean_extracted_text(remedy_match.group(1))
            symptom_text = clean_extracted_text(symptom)
            
            # Valider que nous avons des contenus significatifs
            if len(cause_text) > 10 and len(remedy_text) > 10:
                triplet = {
                    'error_code': code,
                    'page_number': page_num,
                    'symptom': symptom_text,
                    'cause': cause_text,
                    'remedy': remedy_text
                }
                all_triplets.append(triplet)
    
    return all_triplets

def clean_extracted_text(text: str) -> str:
    """Nettoie le texte extrait des triplets"""
    if not text:
        return ""
    
    # Supprimer les retours Ã  la ligne multiples
    text = re.sub(r'\n+', ' ', text)
    
    # Supprimer les espaces multiples
    text = re.sub(r'\s+', ' ', text)
    
    # Supprimer les caractÃ¨res de contrÃ´le indÃ©sirables
    text = re.sub(r'[^\x20-\x7E\xC0-\xFF]', '', text)
    
    # Nettoyer les dÃ©buts/fins
    text = text.strip()
    
    # Supprimer les artefacts OCR courants
    text = re.sub(r'\$\.\$', '', text)  # Artefacts comme $.$
    text = re.sub(r'\^[0-9]', '', text)  # Artefacts comme ^4, ^5
    
    return text

def get_equipment_name() -> str:
    """Demande Ã  l'utilisateur de saisir le nom de l'Ã©quipement"""
    print("\n" + "="*60)
    print("ğŸ”§ CONFIGURATION DE L'Ã‰QUIPEMENT")
    print("="*60)
    print("ğŸ“‹ Veuillez spÃ©cifier le nom de l'Ã©quipement pour ce document.")
    print("ğŸ’¡ Exemples: 'Robot FANUC R-30iB', 'Machine CNC', 'Soudeuse Arc', etc.")
    print()
    
    while True:
        equipment = input("ğŸ­ Nom de l'Ã©quipement: ").strip()
        if equipment and len(equipment) >= 2:
            return equipment
        else:
            print("âš ï¸ Veuillez entrer un nom d'Ã©quipement valide (au moins 2 caractÃ¨res)")

def save_triplets_to_csv(triplets: List[Dict[str, Any]], pdf_filename: str, equipment: str, output_path: Path):
    """Sauvegarde les triplets au format CSV avec les colonnes demandÃ©es"""
    
    # CrÃ©er le rÃ©pertoire de sortie s'il n'existe pas
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Ã‰crire le CSV
    with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
        fieldnames = ['URL', 'equipment', 'page', 'symptom', 'cause', 'remedy']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        
        # Ã‰crire l'en-tÃªte
        writer.writeheader()
        
        # Ã‰crire les donnÃ©es
        for triplet in triplets:
            writer.writerow({
                'URL': pdf_filename,
                'equipment': equipment,
                'page': triplet['page_number'],
                'symptom': triplet['symptom'],
                'cause': triplet['cause'],
                'remedy': triplet['remedy']
            })

def display_extraction_summary(triplets: List[Dict[str, Any]], doc_id: str, equipment: str):
    """Affiche un rÃ©sumÃ© de l'extraction"""
    print(f"\nğŸ“Š RÃ‰SUMÃ‰ DE L'EXTRACTION")
    print(f"{'='*60}")
    print(f"ğŸ“„ Document: {doc_id}")
    print(f"ğŸ­ Ã‰quipement: {equipment}")
    print(f"âœ… Triplets extraits: {len(triplets):,}")
    
    if triplets:
        # Statistiques par page
        pages_with_triplets = set(t['page_number'] for t in triplets)
        print(f"ğŸ“– Pages concernÃ©es: {len(pages_with_triplets)}")
        print(f"ğŸ“Š Moyenne par page: {len(triplets) / len(pages_with_triplets):.1f} triplets")
        
        # Codes d'erreur uniques
        unique_codes = set(t['error_code'] for t in triplets)
        print(f"ğŸš¨ Codes d'erreur uniques: {len(unique_codes)}")
        
        # Exemple de triplet
        example = triplets[0]
        print(f"\nğŸ“‹ PREMIER TRIPLET EXTRAIT:")
        print(f"{'â”€'*60}")
        print(f"ğŸ”¸ Page: {example['page_number']}")
        print(f"ğŸ”¸ Code: {example['error_code']}")
        print(f"ğŸ”¸ SymptÃ´me: {example['symptom'][:80]}{'...' if len(example['symptom']) > 80 else ''}")
        print(f"ğŸ”¸ Cause: {example['cause'][:80]}{'...' if len(example['cause']) > 80 else ''}")
        print(f"ğŸ”¸ RemÃ¨de: {example['remedy'][:80]}{'...' if len(example['remedy']) > 80 else ''}")
    
    print()

def process_document(json_file: Path, output_dir: Path) -> bool:
    """Traite un document JSON et extrait les triplets SCR"""
    
    try:
        # Charger le document JSON
        with open(json_file, 'r', encoding='utf-8') as f:
            doc_data = json.load(f)
        
        doc_id = doc_data['document_id']
        pages = doc_data['pages']
        
        print(f"ğŸ“„ Traitement de: {doc_id}")
        print(f"ğŸ“– Pages Ã  analyser: {len(pages)}")
        
        # Demander le nom de l'Ã©quipement
        equipment = get_equipment_name()
        
        print(f"\nğŸ” Extraction des triplets SCR en cours...")
        
        # Extraire les triplets
        triplets = extract_scr_triplets_with_pages(pages)
        
        if not triplets:
            print(f"âš ï¸ Aucun triplet SCR trouvÃ© dans {doc_id}")
            return False
        
        # Nom du fichier PDF original (supposÃ© Ãªtre le mÃªme que le JSON)
        pdf_filename = f"{doc_id}.pdf"
        
        # Chemin de sortie CSV
        csv_filename = f"{doc_id}_scr_triplets.csv"
        csv_path = output_dir / csv_filename
        
        # Sauvegarder en CSV
        save_triplets_to_csv(triplets, pdf_filename, equipment, csv_path)
        
        # Afficher le rÃ©sumÃ©
        display_extraction_summary(triplets, doc_id, equipment)
        
        print(f"ğŸ’¾ SauvegardÃ©: {csv_path}")
        print(f"âœ… Extraction terminÃ©e avec succÃ¨s!")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur lors du traitement de {json_file}: {e}")
        return False

def main():
    try:
        print("ğŸš€ Extraction des triplets SymptÃ´me-Cause-RemÃ¨de")
        print("="*60)
        
        # Charger la configuration (gÃ©rer l'exÃ©cution depuis scripts/)
        config_path = "config/settings.yaml"
        if not os.path.exists(config_path):
            config_path = "../config/settings.yaml"
            
        settings = load_settings(config_path)
        
        # Chemins avec ajustement pour scripts/
        base_json_dir = Path(settings["paths"]["json_documents"])
        
        # Utiliser extract_scr du config ou chemin par dÃ©faut
        if "extract_scr" in settings["paths"]:
            base_output_dir = Path(settings["paths"]["extract_scr"])
        else:
            base_output_dir = Path("data/extract_scr")  # Chemin par dÃ©faut
        
        # Ajuster les chemins si on exÃ©cute depuis scripts/
        if not base_json_dir.exists():
            base_json_dir = Path("..") / base_json_dir
            base_output_dir = Path("..") / base_output_dir
        
        json_dir = base_json_dir / "intelligent"
        output_dir = base_output_dir
        
        # VÃ©rifier que le rÃ©pertoire JSON existe
        if not json_dir.exists():
            print(f"âŒ Le rÃ©pertoire {json_dir} n'existe pas!")
            print(f"ğŸ’¡ ExÃ©cutez d'abord: python 01_extract_text_PyMuPDF_intelligent.py")
            return
        
        # CrÃ©er le rÃ©pertoire de sortie
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Trouver les fichiers JSON
        json_files = list(json_dir.glob("*.json"))
        
        if not json_files:
            print(f"âŒ Aucun fichier JSON trouvÃ© dans {json_dir}")
            return
        
        print(f"ğŸ“š {len(json_files)} document(s) Ã  traiter")
        
        # Traiter chaque document
        successful_extractions = 0
        
        for json_file in json_files:
            print(f"\n{'='*60}")
            if process_document(json_file, output_dir):
                successful_extractions += 1
        
        # RÃ©sumÃ© final
        print(f"\nğŸ‰ EXTRACTION TERMINÃ‰E")
        print(f"{'='*60}")
        print(f"âœ… Documents traitÃ©s avec succÃ¨s: {successful_extractions}/{len(json_files)}")
        print(f"ğŸ“ Fichiers CSV gÃ©nÃ©rÃ©s dans: {output_dir}")
        print(f"ğŸ’¡ PrÃªt pour analyse ou intÃ©gration dans Knowledge Graph")
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()