"""
Pour lancer:
docker run --rm \
  -v $(pwd)/.env:/app/.env \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/config:/app/config \
  -v $(pwd)/pipeline_step:/app/pipeline_step \
  --network host \
  diagnosis-app \
  poetry run python pipeline_step/knowledge_graph_setup/build_sparse_knowledge_graph.py
"""

"""
Construction Knowledge Graph Sparse avec support Cloud/Local
Structure simple 1:1:1 sans densification
"""

import os
import pandas as pd
from neo4j import GraphDatabase
from dotenv import load_dotenv
import yaml

# === Chargement des variables d'environnement (.env) ===
load_dotenv()

def load_settings():
    """Charge la configuration depuis settings.yaml"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(script_dir, "..", "..", "config", "settings.yaml")
    with open(config_path, 'r', encoding='utf-8') as file:
        return yaml.safe_load(file)

def get_neo4j_connection(kg_type="sparse"):
    """
    ğŸŒ Connexion intelligente Cloud/Local
    kg_type: "dense", "sparse", ou "dense_sc"
    """
    load_dotenv()
    
    # PrioritÃ© au Cloud si activÃ©
    cloud_enabled = os.getenv("NEO4J_CLOUD_ENABLED", "false").lower() == "true"
    
    if cloud_enabled:
        print(f"ğŸŒ MODE CLOUD pour {kg_type.upper()}")
        
        if kg_type == "dense":
            uri = os.getenv("NEO4J_DENSE_CLOUD_URI")
            password = os.getenv("NEO4J_DENSE_CLOUD_PASS")
        elif kg_type == "sparse":
            uri = os.getenv("NEO4J_SPARSE_CLOUD_URI")
            password = os.getenv("NEO4J_SPARSE_CLOUD_PASS")
        elif kg_type == "dense_sc":
            uri = os.getenv("NEO4J_DENSE_SC_CLOUD_URI")
            password = os.getenv("NEO4J_DENSE_SC_CLOUD_PASS")
        
        if uri and password:
            print(f"ğŸ”Œ Connexion Cloud {kg_type}: {uri}")
            return GraphDatabase.driver(uri, auth=("neo4j", password))
        else:
            print(f"âŒ Credentials cloud manquants pour {kg_type}")
            cloud_enabled = False
    
    # Fallback Local
    print(f"ğŸ  MODE LOCAL pour {kg_type.upper()}")
    
    if kg_type == "dense":
        uri = os.getenv("NEO4J_URI_DENSE", "bolt://host.docker.internal:7687")
        user = os.getenv("NEO4J_USER_DENSE", "neo4j")
        password = os.getenv("NEO4J_PASS_DENSE", "password")
    elif kg_type == "sparse":
        uri = os.getenv("NEO4J_URI_SPARSE", "bolt://host.docker.internal:7689")
        user = os.getenv("NEO4J_USER_SPARSE", "neo4j")
        password = os.getenv("NEO4J_PASS_SPARSE", "password")
    elif kg_type == "dense_sc":
        uri = os.getenv("NEO4J_URI_DENSE_SC", "bolt://host.docker.internal:7690")
        user = os.getenv("NEO4J_USER_DENSE_SC", "neo4j")
        password = os.getenv("NEO4J_PASS_DENSE_SC", "password")
    
    print(f"ğŸ”Œ Connexion Local {kg_type}: {uri}")
    return GraphDatabase.driver(uri, auth=(user, password))

# === PARAMÃˆTRES ===
script_dir = os.path.dirname(os.path.abspath(__file__))
CSV_PATH = os.path.join(script_dir, "..", "..", "data", "knowledge_base", "scr_triplets", "doc-R-30iB_scr_triplets.csv")

# === CONNEXION NEO4J ===
driver = get_neo4j_connection("sparse")

def find_csv_file():
    """Trouve le fichier CSV en testant plusieurs chemins"""
    # Chemin principal
    main_path = CSV_PATH
    
    # Chemins alternatifs
    alt_paths = [
        os.path.join(script_dir, "..", "..", "data", "extract_scr", "doc-R-30iB_scr_triplets.csv"),
        os.path.join(script_dir, "..", "data", "extract_scr", "doc-R-30iB_scr_triplets.csv"),
        os.path.join(script_dir, "data", "extract_scr", "doc-R-30iB_scr_triplets.csv"),
        os.path.join("data", "extract_scr", "doc-R-30iB_scr_triplets.csv"),
        os.path.join("data", "knowledge_base", "scr_triplets", "doc-R-30iB_scr_triplets.csv")
    ]
    
    # Test du chemin principal
    if os.path.exists(main_path):
        return main_path
    
    # Test des chemins alternatifs
    print("ğŸ“‚ VÃ©rification chemins alternatifs...")
    for alt_path in alt_paths:
        if os.path.exists(alt_path):
            print(f"âœ… Fichier trouvÃ©: {alt_path}")
            return alt_path
    
    # Aucun fichier trouvÃ©
    raise FileNotFoundError(f"Fichier CSV introuvable dans tous les chemins testÃ©s")

# === CHARGEMENT ET NETTOYAGE DES DONNÃ‰ES ===
def load_and_clean_data():
    """Charge et nettoie les donnÃ©es CSV en supprimant les doublons"""
    print("ğŸ“‚ Chargement du fichier CSV...")
    
    try:
        csv_path = find_csv_file()
        df = pd.read_csv(csv_path)
        print(f"âœ… Fichier CSV chargÃ©: {csv_path}")
    except FileNotFoundError as e:
        print(f"âŒ ERREUR: {str(e)}")
        raise
    
    print(f"ğŸ“Š DonnÃ©es initiales : {len(df)} lignes")
    print(f"ğŸ“‹ Colonnes dÃ©tectÃ©es : {list(df.columns)}")
    
    # VÃ©rification que la colonne equipment existe
    if 'equipment' not in df.columns:
        print("âŒ ERREUR: Colonne 'equipment' manquante dans le CSV")
        raise ValueError("Colonne 'equipment' requise")
    
    # Suppression des lignes avec des valeurs manquantes (incluant equipment)
    df.dropna(subset=["symptom", "cause", "remedy", "equipment"], inplace=True)
    print(f"ğŸ“Š AprÃ¨s suppression NaN : {len(df)} lignes")
    
    # Suppression des doublons exacts (mÃªme symptom, cause, remedy, equipment)
    df_before_dedup = len(df)
    df = df.drop_duplicates(subset=["symptom", "cause", "remedy", "equipment"], keep="first")
    duplicates_removed = df_before_dedup - len(df)
    print(f"ğŸ“Š Doublons supprimÃ©s : {duplicates_removed}")
    print(f"ğŸ“Š DonnÃ©es finales : {len(df)} lignes")
    
    # Affichage des Ã©quipements uniques
    unique_equipment = df['equipment'].unique()
    print(f"ğŸ­ Ã‰quipements uniques trouvÃ©s : {len(unique_equipment)}")
    for eq in sorted(unique_equipment):
        count = len(df[df['equipment'] == eq])
        print(f"   â€¢ {eq}: {count} triplets")
    
    return df

# === NETTOYAGE COMPLET DE LA BASE ===
def clear_database(tx):
    """Vide complÃ¨tement la base Neo4j pour un fresh start"""
    tx.run("MATCH (n) DETACH DELETE n")

# === INSERTION DES TRIPLETS SCR (APPROCHE SPARSE) ===
def insert_triplets_sparse(tx, s, c, r, equipment, triplet_id):
    """Insert un triplet SCR avec equipment en prÃ©servant TOUS les nÅ“uds"""
    tx.run("""
        CREATE (sym:Symptom {name: $s, equipment: $equipment, triplet_id: $triplet_id})
        CREATE (cause:Cause {name: $c, equipment: $equipment, triplet_id: $triplet_id})
        CREATE (rem:Remedy {name: $r, equipment: $equipment, triplet_id: $triplet_id})
        CREATE (sym)-[:CAUSES]->(cause)
        CREATE (cause)-[:TREATED_BY]->(rem)
    """, s=s, c=c, r=r, equipment=equipment, triplet_id=triplet_id)

# === STATISTIQUES ET VALIDATION ===
def print_graph_stats(tx):
    """Affiche les statistiques du graphe sparse avec equipment"""
    result = tx.run("""
        RETURN 
        count{(s:Symptom)} as symptoms,
        count{(c:Cause)} as causes, 
        count{(r:Remedy)} as remedies,
        count{()-[:CAUSES]->()} as causes_relations,
        count{()-[:TREATED_BY]->()} as treated_by_relations
    """)
    
    stats = result.single()
    print("\nğŸ“ˆ STATISTIQUES DU GRAPHE SPARSE :")
    print(f"   â€¢ SymptÃ´mes : {stats['symptoms']}")
    print(f"   â€¢ Causes : {stats['causes']}")
    print(f"   â€¢ RemÃ¨des : {stats['remedies']}")
    print(f"   â€¢ Relations CAUSES : {stats['causes_relations']}")
    print(f"   â€¢ Relations TREATED_BY : {stats['treated_by_relations']}")
    print(f"   â€¢ TOTAL nÅ“uds : {stats['symptoms'] + stats['causes'] + stats['remedies']}")
    print(f"   â€¢ TOTAL relations : {stats['causes_relations'] + stats['treated_by_relations']}")
    
    # Statistiques par Ã©quipement
    print("\nğŸ­ RÃ‰PARTITION PAR Ã‰QUIPEMENT :")
    eq_result = tx.run("""
        MATCH (s:Symptom)
        WHERE s.equipment IS NOT NULL
        RETURN s.equipment as equipment, count(s) as symptom_count
        ORDER BY symptom_count DESC
    """)
    
    for record in eq_result:
        equipment = record['equipment']
        count = record['symptom_count']
        print(f"   â€¢ {equipment}: {count} symptÃ´mes")

def check_orphaned_nodes(tx):
    """VÃ©rifie s'il y a des nÅ“uds orphelins dans le graphe sparse"""
    result = tx.run("""
        MATCH (n)
        WHERE NOT (n)--()
        RETURN count(n) as orphaned_nodes
    """)
    
    orphaned = result.single()["orphaned_nodes"]
    if orphaned > 0:
        print(f"   âš ï¸  NÅ“uds orphelins dÃ©tectÃ©s : {orphaned}")
    else:
        print(f"   âœ… Aucun nÅ“ud orphelin")

# === PIPELINE PRINCIPAL (SPARSE + EQUIPMENT + CLOUD) ===
def main():
    """Pipeline de crÃ©ation d'une Knowledge Base SPARSE avec equipment et support cloud"""
    print("ğŸš€ DÃ‰MARRAGE DU PIPELINE NEO4J SPARSE + EQUIPMENT + CLOUD")
    print("=" * 70)
    print("ğŸ“ Mode : Knowledge Base SPARSE (structure simple 1:1:1)")
    print("ğŸŒ Support : Cloud/Local automatique")
    print("ğŸ†• PropriÃ©tÃ©s equipment sur chaque nÅ“ud")
    print()
    
    try:
        # Test de connexion
        print("ğŸ”Œ Test de connexion...")
        with driver.session() as session:
            result = session.run("RETURN 'Connected to Sparse KG!' as message")
            message = result.single()["message"]
            print(f"âœ… {message}")
        
        # Chargement et nettoyage des donnÃ©es
        df = load_and_clean_data()
        
        with driver.session() as session:
            print("\nğŸ“Œ Ã‰tape 1 - Nettoyage de la base Neo4j Sparse...")
            session.execute_write(clear_database)
            
            print("ğŸ“Œ Ã‰tape 2 - Insertion des triplets SCR avec equipment...")
            for idx, row in df.iterrows():
                session.execute_write(insert_triplets_sparse, 
                                    row["symptom"], 
                                    row["cause"], 
                                    row["remedy"],
                                    row["equipment"],
                                    idx)  # ID unique pour traÃ§abilitÃ©
                if (idx + 1) % 1000 == 0:
                    print(f"   â€¢ {idx + 1}/{len(df)} triplets insÃ©rÃ©s...")
            
            print("ğŸ“Œ Ã‰tape 3 - GÃ©nÃ©ration des statistiques...")
            session.execute_read(print_graph_stats)
            session.execute_read(check_orphaned_nodes)
        
        print("\nâœ… CRÃ‰ATION KNOWLEDGE BASE SPARSE + EQUIPMENT TERMINÃ‰E !")
        print("ğŸ“Š CaractÃ©ristiques :")
        print("   â€¢ Structure linÃ©aire : 1 SymptÃ´me â†’ 1 Cause â†’ 1 RemÃ¨de")
        print("   â€¢ PropriÃ©tÃ© equipment sur chaque nÅ“ud")
        print("   â€¢ AUCUNE densification (pas de mÃ©trique hybride)")
        print("   â€¢ AUCUNE dÃ©duplication des causes/remÃ¨des")
        print("   â€¢ PrÃ©servation totale des doublons (sauf triplets identiques)")
        print("   â€¢ Relations 1:1:1 strictes du CSV original")
        print("   â€¢ TraÃ§abilitÃ© parfaite via triplet_id")
        print("   â€¢ ğŸŒ Compatible Cloud/Local automatique")
        print()
        print("ğŸ”— Connectez-vous Ã  Neo4j Browser pour explorer")
        print("ğŸ’¡ Comparez avec les Knowledge Bases Dense !")
        print()
        print("ğŸ” RequÃªte test equipment :")
        print("   MATCH (s:Symptom) WHERE s.equipment CONTAINS 'FANUC' RETURN s LIMIT 5")
        
    except FileNotFoundError:
        csv_path = find_csv_file() if 'find_csv_file' in locals() else CSV_PATH
        print(f"âŒ ERREUR : Fichier CSV introuvable : {csv_path}")
        print("   VÃ©rifiez que le fichier existe et que le chemin est correct.")
    except Exception as e:
        print(f"âŒ ERREUR INATTENDUE : {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        driver.close()

if __name__ == "__main__":
    main()