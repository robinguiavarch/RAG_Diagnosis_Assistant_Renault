#!/usr/bin/env python3
"""
Script graph_retrieval_13.py - Interface pour tester le contexte Knowledge Graph Dense

Objectif : Permettre Ã  l'utilisateur de saisir une requÃªte et voir exactement 
le contexte structurÃ© qui sera fourni au LLM dans le pipeline RAG.

Usage:

# Test d'une requÃªte spÃ©cifique
./docker-commands.sh test_graph_retrieval --query "ACAL-006 TPE operation error"

# Mode interactif
./docker-commands.sh test_graph_retrieval --interactive

# Mode batch
./docker-commands.sh test_graph_retrieval --batch

# Voir le menu complet
./docker-commands.sh menu

"""

import os
import sys
import argparse
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent.parent))
try:
    from core.retrieval_graph.dense_kg_querier import DenseKGQuerier
    kg_dense_query = DenseKGQuerier()
    
except ImportError as e:
    print(f"âŒ Erreur d'import kg_dense_query: {e}")
    print("ğŸ’¡ VÃ©rifiez que kg_dense_query.py est dans src/graph_retrieval/")
    sys.exit(1)

def display_banner():
    """Affiche la banniÃ¨re du script"""
    print("ğŸ” GRAPH RETRIEVAL TESTER - Knowledge Base Dense")
    print("=" * 60)
    print("ğŸ¯ Objectif : Tester le contexte fourni au LLM")
    print("ğŸ“‹ Source : Knowledge Graph Dense via kg_dense_query.py")
    print()

def display_system_info():
    """Affiche les informations systÃ¨me"""
    print("ğŸ“Š INFORMATIONS SYSTÃˆME :")
    try:
        # Test de disponibilitÃ© des composants
        config = kg_dense_query.load_settings()
        print(f"   âœ… Configuration chargÃ©e")
        print(f"   ğŸ“¦ ModÃ¨le embedding : {config['models']['embedding_model']}")
        print(f"   ğŸ¯ Seuil similaritÃ© : {config['retrieval']['symptom_similarity_threshold']}")
        print(f"   ğŸ”¢ Top-K symptÃ´mes : {config['retrieval']['symptom_top_k']}")
        
        # Test Neo4j
        stats = kg_dense_query.get_kb_stats()
        print(f"   âœ… Neo4j Dense accessible")
        print(f"   ğŸ“ˆ SymptÃ´mes dans KB : {stats['symptoms']}")
        print(f"   ğŸ“ˆ Causes dans KB : {stats['causes']}")
        print(f"   ğŸ“ˆ RemÃ¨des dans KB : {stats['remedies']}")
        
        # Test FAISS
        try:
            index, metadata = kg_dense_query.load_symptom_index()
            print(f"   âœ… Index FAISS disponible")
            print(f"   ğŸ“Š SymptÃ´mes indexÃ©s : {index.ntotal}")
            print(f"   ğŸ§  Dimension embeddings : {index.d}")
        except FileNotFoundError:
            print(f"   âš ï¸  Index FAISS non trouvÃ© - Lancez create_symptom_faiss_dense_11.py")
            
    except Exception as e:
        print(f"   âŒ Erreur systÃ¨me : {e}")
    print()

def format_context_for_display(context: str, query: str) -> str:
    """Formate le contexte pour un affichage clair"""
    separator = "=" * 80
    
    formatted = f"""
{separator}
ğŸ¤– CONTEXTE QUI SERA FOURNI AU LLM
{separator}

ğŸ“ REQUÃŠTE UTILISATEUR :
"{query}"

ğŸ“‹ CONTEXTE STRUCTURÃ‰ EXTRAIT :
{'-' * 40}
{context}
{'-' * 40}

ğŸ’¡ ANALYSE DU CONTEXTE :
â€¢ Ce contexte sera injectÃ© dans le prompt du LLM
â€¢ Le LLM utilisera ces informations structurÃ©es pour gÃ©nÃ©rer sa rÃ©ponse
â€¢ Plus le contexte est riche, plus la rÃ©ponse sera prÃ©cise et actionnable

{separator}
"""
    return formatted

def analyze_context_quality(context: str) -> dict:
    """Analyse la qualitÃ© du contexte retournÃ©"""
    analysis = {
        'has_content': 'No relevant' not in context and 'Error' not in context,
        'triplet_count': context.count('Triplet ') if 'Triplet ' in context else 0,
        'symptom_count': context.count('Symptom:'),
        'cause_count': context.count('Cause:'),
        'remedy_count': context.count('Remedy:'),
        'avg_similarity': 0.0
    }
    
    # Extraction des scores de similaritÃ©
    import re
    similarity_scores = re.findall(r'similaritÃ©: ([\d.]+)', context)
    if similarity_scores:
        scores = [float(score) for score in similarity_scores]
        analysis['avg_similarity'] = sum(scores) / len(scores)
    
    return analysis

def display_context_analysis(analysis: dict):
    """Affiche l'analyse du contexte"""
    print("ğŸ”¬ ANALYSE DE LA QUALITÃ‰ DU CONTEXTE :")
    print(f"   ğŸ“Š Contexte trouvÃ© : {'âœ… Oui' if analysis['has_content'] else 'âŒ Non'}")
    print(f"   ğŸ”¢ Triplets trouvÃ©s : {analysis['triplet_count']}")
    print(f"   ğŸ¯ SymptÃ´mes matchÃ©s : {analysis['symptom_count']}")
    print(f"   ğŸ” Causes identifiÃ©es : {analysis['cause_count']}")
    print(f"   ğŸ’¡ RemÃ¨des suggÃ©rÃ©s : {analysis['remedy_count']}")
    if analysis['avg_similarity'] > 0:
        print(f"   ğŸ“ˆ SimilaritÃ© moyenne : {analysis['avg_similarity']:.3f}")
    
    # Recommandations
    print("\nğŸ’­ RECOMMANDATIONS :")
    if not analysis['has_content']:
        print("   âš ï¸  Aucun contexte trouvÃ© - Essayez une requÃªte plus spÃ©cifique")
    elif analysis['triplet_count'] < 2:
        print("   ğŸ’¡ Peu de triplets - La requÃªte pourrait Ãªtre plus gÃ©nÃ©rale")
    elif analysis['triplet_count'] > 5:
        print("   âœ… Bon contexte - Le LLM aura suffisamment d'informations")
    else:
        print("   âœ… Contexte Ã©quilibrÃ© - Bonne base pour la gÃ©nÃ©ration LLM")

def test_single_query(query: str, format_type: str = "detailed", show_analysis: bool = True):
    """Teste une requÃªte unique et affiche le rÃ©sultat"""
    print(f"ğŸ” Test de la requÃªte : '{query}'")
    print(f"ğŸ“‹ Format demandÃ© : {format_type}")
    print()
    
    try:
        # RÃ©cupÃ©ration du contexte
        print("â³ Recherche en cours...")
        context = kg_dense_query.get_structured_context(query, format_type)
        
        # Affichage du contexte formatÃ©
        formatted_context = format_context_for_display(context, query)
        print(formatted_context)
        
        # Analyse de la qualitÃ© si demandÃ©e
        if show_analysis and format_type == "detailed":
            analysis = analyze_context_quality(context)
            display_context_analysis(analysis)
        
        return context
        
    except Exception as e:
        print(f"âŒ Erreur lors de la rÃ©cupÃ©ration du contexte : {e}")
        return None

def interactive_mode():
    """Mode interactif pour tester plusieurs requÃªtes"""
    print("ğŸ® MODE INTERACTIF ACTIVÃ‰")
    print("ğŸ’¡ Tapez 'quit' ou 'exit' pour sortir")
    print("ğŸ’¡ Tapez 'help' pour voir les commandes")
    print()
    
    while True:
        try:
            # Saisie utilisateur
            user_input = input("ğŸ” Entrez votre requÃªte (ou 'help'): ").strip()
            
            if not user_input:
                continue
                
            # Commandes spÃ©ciales
            if user_input.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ Au revoir !")
                break
                
            elif user_input.lower() in ['help', 'h']:
                print("\nğŸ“‹ COMMANDES DISPONIBLES :")
                print("   help          - Afficher cette aide")
                print("   quit/exit     - Quitter le mode interactif")
                print("   stats         - Afficher les statistiques systÃ¨me")
                print("   compact       - Format compact pour la prochaine requÃªte")
                print("   detailed      - Format dÃ©taillÃ© pour la prochaine requÃªte")
                print("   json          - Format JSON pour la prochaine requÃªte")
                print("   <votre_requÃªte> - Tester une requÃªte symptÃ´me")
                print()
                continue
                
            elif user_input.lower() == 'stats':
                display_system_info()
                continue
                
            elif user_input.lower() in ['compact', 'detailed', 'json']:
                print(f"ğŸ“‹ Format dÃ©fini sur : {user_input}")
                continue
            
            # Test de la requÃªte
            print("-" * 60)
            test_single_query(user_input, format_type="detailed", show_analysis=True)
            print("-" * 60)
            print()
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Interruption utilisateur - Au revoir !")
            break
        except Exception as e:
            print(f"âŒ Erreur : {e}")

def batch_test_mode(queries: list):
    """Mode batch pour tester plusieurs requÃªtes prÃ©dÃ©finies"""
    print(f"ğŸš€ MODE BATCH - Test de {len(queries)} requÃªtes")
    print()
    
    results = []
    
    for i, query in enumerate(queries, 1):
        print(f"ğŸ“ Test {i}/{len(queries)}")
        context = test_single_query(query, format_type="compact", show_analysis=False)
        results.append({
            'query': query,
            'context': context,
            'success': context is not None and 'No relevant' not in context
        })
        print("\n" + "="*80 + "\n")
    
    # RÃ©sumÃ© des rÃ©sultats
    print("ğŸ“Š RÃ‰SUMÃ‰ DES TESTS BATCH :")
    success_count = sum(1 for r in results if r['success'])
    print(f"   âœ… RequÃªtes avec contexte : {success_count}/{len(queries)}")
    print(f"   âŒ RequÃªtes sans contexte : {len(queries) - success_count}/{len(queries)}")
    
    # DÃ©tail des Ã©checs
    failures = [r for r in results if not r['success']]
    if failures:
        print("\nâš ï¸  REQUÃŠTES SANS CONTEXTE :")
        for f in failures:
            print(f"   â€¢ '{f['query']}'")

def main():
    """Fonction principale"""
    parser = argparse.ArgumentParser(
        description="Testeur de contexte Knowledge Graph Dense",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:
  python scripts/graph_retrieval_13.py
  python scripts/graph_retrieval_13.py --query "ACAL-006 TPE operation error"
  python scripts/graph_retrieval_13.py --interactive
  python scripts/graph_retrieval_13.py --batch
  python scripts/graph_retrieval_13.py --query "robot not working" --format json
        """
    )
    
    parser.add_argument("--query", "-q", type=str, 
                       help="RequÃªte Ã  tester (mode single)")
    parser.add_argument("--format", "-f", choices=["detailed", "compact", "json"],
                       default="detailed", help="Format de sortie du contexte")
    parser.add_argument("--interactive", "-i", action="store_true",
                       help="Mode interactif")
    parser.add_argument("--batch", "-b", action="store_true",
                       help="Mode batch avec requÃªtes prÃ©dÃ©finies")
    parser.add_argument("--no-analysis", action="store_true",
                       help="DÃ©sactiver l'analyse de qualitÃ©")
    parser.add_argument("--no-banner", action="store_true",
                       help="Masquer la banniÃ¨re")
    
    args = parser.parse_args()
    
    # Affichage de la banniÃ¨re
    if not args.no_banner:
        display_banner()
        display_system_info()
    
    # Mode de fonctionnement
    if args.query:
        # Mode requÃªte unique
        test_single_query(
            args.query, 
            format_type=args.format, 
            show_analysis=not args.no_analysis
        )
        
    elif args.interactive:
        # Mode interactif
        interactive_mode()
        
    elif args.batch:
        # Mode batch avec requÃªtes prÃ©dÃ©finies
        test_queries = [
            "ACAL-006 TPE operation error",
            "motor overheating", 
            "engine not starting",
            "robot malfunction",
            "temperature too high",
            "power failure",
            "conveyor belt stuck",
            "sensor error",
            "hydraulic leak",
            "brake not working",
            "communication error"
        ]
        batch_test_mode(test_queries)
        
    else:
        # Mode par dÃ©faut : interactif
        interactive_mode()

if __name__ == "__main__":
    main()